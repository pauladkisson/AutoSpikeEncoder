{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BenchmarkSim.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "payCKL-mqhfP"
      },
      "source": [
        "# Benchmark Simulated Data Using SNR cutoff and Holdout Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGA2oroEWDk1"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydNiMYYUstbP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46e92ce1-37ab-4b6c-c121-ad5412280873"
      },
      "source": [
        "## Mount Google Drive Data (If using Google Colaboratory)\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/gdrive')\n",
        "except:\n",
        "    print(\"Mounting Failed.\")\n",
        "\n",
        "## External Libraries\n",
        "import sys\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from autoencode import AEEnsemble\n",
        "from datasets import UnsupervisedDataset, SupervisedDataset, BenchmarkDataset\n",
        "from sklearn.mixture import GaussianMixture\n",
        "!pip install graspologic\n",
        "from graspologic.utils import remap_labels\n",
        "import seaborn as sns\n",
        "from sklearn.manifold import TSNE\n",
        "tsne = TSNE(n_components=2)\n",
        "sns.set_theme()\n",
        "sns.set_context(\"paper\")\n",
        "\n",
        "# General Data Directory ##TODO: Please fill in the appropriate directory\n",
        "os.chdir(\"/content/\")\n",
        "data_dir = \"./gdrive/MyDrive/pedreira\"\n",
        "results_dir = \"./gdrive/MyDrive/results\""
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "Requirement already satisfied: graspologic in /usr/local/lib/python3.7/dist-packages (0.1.0)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from graspologic) (0.11.1)\n",
            "Requirement already satisfied: numpy>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from graspologic) (1.19.5)\n",
            "Requirement already satisfied: anytree>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from graspologic) (2.8.0)\n",
            "Requirement already satisfied: hyppo==0.1.3 in /usr/local/lib/python3.7/dist-packages (from graspologic) (0.1.3)\n",
            "Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.7/dist-packages (from graspologic) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from graspologic) (1.4.1)\n",
            "Requirement already satisfied: graspologic-native in /usr/local/lib/python3.7/dist-packages (from graspologic) (0.1.0)\n",
            "Requirement already satisfied: gensim<=3.9.0,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from graspologic) (3.8.3)\n",
            "Requirement already satisfied: matplotlib<=3.3.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from graspologic) (3.2.2)\n",
            "Requirement already satisfied: joblib>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from graspologic) (1.0.1)\n",
            "Requirement already satisfied: POT>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from graspologic) (0.7.0)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.7/dist-packages (from graspologic) (2.5.1)\n",
            "Requirement already satisfied: umap-learn>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from graspologic) (0.5.1)\n",
            "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.7/dist-packages (from seaborn>=0.11.0->graspologic) (1.1.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from anytree>=2.8.0->graspologic) (1.15.0)\n",
            "Requirement already satisfied: numba>=0.46 in /usr/local/lib/python3.7/dist-packages (from hyppo==0.1.3->graspologic) (0.51.2)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim<=3.9.0,>=3.8.0->graspologic) (5.0.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<=3.3.0,>=3.0.0->graspologic) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<=3.3.0,>=3.0.0->graspologic) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib<=3.3.0,>=3.0.0->graspologic) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<=3.3.0,>=3.0.0->graspologic) (2.8.1)\n",
            "Requirement already satisfied: cython>=0.23 in /usr/local/lib/python3.7/dist-packages (from POT>=0.7.0->graspologic) (0.29.22)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.1->graspologic) (4.4.2)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.7/dist-packages (from umap-learn>=0.4.6->graspologic) (0.5.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23->seaborn>=0.11.0->graspologic) (2018.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.46->hyppo==0.1.3->graspologic) (56.0.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.46->hyppo==0.1.3->graspologic) (0.34.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUkQnuJ3THva"
      },
      "source": [
        "Define Datasets and AutoEncoder Ensemble"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8jI7ndcSiqN",
        "outputId": "8df15fd4-7248-4397-a157-9ded28453ebd"
      },
      "source": [
        "sup_data = BenchmarkDataset(data_dir)\n",
        "test_idx = []\n",
        "for i in range(2, 21):\n",
        "    test_idx.append(list(sup_data.num_units).index(i))\n",
        "train_idx = np.arange(len(sup_data))\n",
        "not_test_mask = np.logical_not(np.isin(train_idx, test_idx))\n",
        "train_idx = train_idx[not_test_mask]\n",
        "train_data = torch.utils.data.Subset(sup_data, train_idx)\n",
        "test_data = torch.utils.data.Subset(sup_data, test_idx)\n",
        "\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "ae = AEEnsemble(\n",
        "    optim=torch.optim.Adam,\n",
        "    convolutional_encoding=False, \n",
        "    batch_size=32, \n",
        "    epochs=50, \n",
        "    lr=(0.001, 0.001, 0.001),\n",
        "    device=device, \n",
        "    activ=nn.ReLU\n",
        ")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cuda:0\n",
            "Using cuda:0\n",
            "Using cuda:0\n",
            "Using cuda:0\n",
            "Using cuda:0\n",
            "Using cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6phQWnjUTMV6"
      },
      "source": [
        "Define Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRLcWaCmTLgx"
      },
      "source": [
        "def gt_gmm(latent_vecs, test_targets):\n",
        "    test_acc = []\n",
        "    test_prec = []\n",
        "    test_recall = []\n",
        "    session_weights = []\n",
        "    remapped_preds = []\n",
        "    for (i, latent), targets in zip(enumerate(latent_vecs), test_targets):\n",
        "        session_weights.append(len(targets))\n",
        "        units = set(targets)\n",
        "        num_units = len(units)\n",
        "        gmm = GaussianMixture(n_components=num_units)\n",
        "        pred = gmm.fit_predict(latent)\n",
        "        remapped_pred = remap_labels(targets, pred)\n",
        "        remapped_preds.append(remapped_pred)\n",
        "        prec = []\n",
        "        recall = []\n",
        "        for unit in units:\n",
        "            TP = np.sum(np.logical_and(remapped_pred==unit, targets==unit))\n",
        "            FP = np.sum(np.logical_and(remapped_pred==unit, targets!=unit))\n",
        "            if FP == 0:\n",
        "                prec.append(1)\n",
        "            else:\n",
        "                prec.append(TP / (TP + FP))\n",
        "            TN = np.sum(np.logical_and(remapped_pred!=unit, targets!=unit))\n",
        "            FN = np.sum(np.logical_and(remapped_pred!=unit, targets==unit))\n",
        "            if FN == 0:\n",
        "                recall.append(1)\n",
        "            else:\n",
        "                recall.append(TP / (TP + FN))\n",
        "\n",
        "        test_prec.append(np.mean(prec))\n",
        "        test_recall.append(np.mean(recall))\n",
        "        test_acc.append(sum(remapped_pred==targets)/len(targets))\n",
        "\n",
        "    session_weights = np.array(session_weights) / sum(session_weights)\n",
        "    avg_acc = np.sum(test_acc*session_weights)\n",
        "    avg_prec = np.mean(test_acc)\n",
        "    avg_recall = np.mean(test_recall)\n",
        "    avg_stats = avg_acc, avg_prec, avg_recall\n",
        "    session_stats = test_acc, test_prec, test_recall\n",
        "    return avg_stats, session_stats, remapped_preds\n",
        "\n",
        "def auto_gmm(latent_vecs, test_targets):\n",
        "    test_acc = []\n",
        "    test_prec = []\n",
        "    test_recall = []\n",
        "    session_weights = []\n",
        "    remapped_preds = []\n",
        "    max_n_comps = 21\n",
        "    for (i, latent), targets in zip(enumerate(latent_vecs), test_targets):\n",
        "        session_weights.append(len(targets))\n",
        "        units = set(targets)\n",
        "        num_units = len(units)\n",
        "        bics = []\n",
        "        preds = []\n",
        "        for n_comps in range(1, max_n_comps+1):\n",
        "            gmm = GaussianMixture(n_components=n_comps)\n",
        "            preds.append(gmm.fit_predict(latent))\n",
        "            bics.append(gmm.bic(latent))\n",
        "        pred = preds[np.argmin(bics)]\n",
        "        print(\"predicted num_units=\", np.argmin(bics)+1)\n",
        "        print(\"true num_units=\", num_units)\n",
        "        remapped_pred = remap_labels(targets, pred)\n",
        "        remapped_preds.append(remapped_pred)\n",
        "        prec = []\n",
        "        recall = []\n",
        "        for unit in units:\n",
        "            TP = np.sum(np.logical_and(remapped_pred==unit, targets==unit))\n",
        "            FP = np.sum(np.logical_and(remapped_pred==unit, targets!=unit))\n",
        "            if FP == 0:\n",
        "                prec.append(1)\n",
        "            else:\n",
        "                prec.append(TP / (TP + FP))\n",
        "            TN = np.sum(np.logical_and(remapped_pred!=unit, targets!=unit))\n",
        "            FN = np.sum(np.logical_and(remapped_pred!=unit, targets==unit))\n",
        "            if FN == 0:\n",
        "                recall.append(1)\n",
        "            else:\n",
        "                recall.append(TP / (TP + FN))\n",
        "\n",
        "        test_prec.append(np.mean(prec))\n",
        "        test_recall.append(np.mean(recall))\n",
        "        test_acc.append(sum(remapped_pred==targets)/len(targets))\n",
        "\n",
        "    session_weights = np.array(session_weights) / sum(session_weights)\n",
        "    avg_acc = np.sum(test_acc*session_weights)\n",
        "    avg_prec = np.mean(test_acc)\n",
        "    avg_recall = np.mean(test_recall)\n",
        "    avg_stats = avg_acc, avg_prec, avg_recall\n",
        "    session_stats = test_acc, test_prec, test_recall\n",
        "    return avg_stats, session_stats, remapped_preds\n",
        "\n",
        "def viz_stats(avg_stats, session_stats, _title, figname):\n",
        "    avg_acc, avg_prec, avg_recall = avg_stats\n",
        "    test_acc, test_prec, test_recall = session_stats\n",
        "    print(\"Average Accuracy=\", avg_acc)\n",
        "    print(\"Average Precision=\", avg_prec)\n",
        "    print(\"Average Recall=\", avg_recall)\n",
        "\n",
        "    fig = plt.figure()\n",
        "    plt.hold = True\n",
        "    plt.plot(np.arange(2, 21), test_acc, label=\"Accuracy\")\n",
        "    plt.plot(np.arange(2, 21), test_prec, label=\"Precision\")\n",
        "    plt.plot(np.arange(2, 21), test_recall, label=\"Recall\")\n",
        "    plt.hold = False\n",
        "    plt.legend()\n",
        "    plt.xlabel(\"True Number of Units (before SNR)\")\n",
        "    plt.ylabel(\"Performance\")\n",
        "    plt.title(_title)\n",
        "    plt.savefig(results_dir+\"/\"+figname)\n",
        "\n",
        "def viz_tsne(unit_nums, latent_vecs, test_targets, remapped_preds, fignames):\n",
        "    for idx, figname in zip(unit_nums, fignames):\n",
        "        i = idx - 2 #accounting for offset since idx=0 has 2 units\n",
        "        latent = latent_vecs[i]\n",
        "        targets = test_targets[i]\n",
        "        remapped_pred = remapped_preds[i]\n",
        "\n",
        "        # Plot tsne\n",
        "        latent_manifold = tsne.fit_transform(latent.cpu())\n",
        "\n",
        "        fig, (ax1, ax2) = plt.subplots(ncols=2, sharex=True, sharey=True)\n",
        "        ax1.set_title(\"Ground Truth Labels\")\n",
        "        ax1.set_xticks([])\n",
        "        ax1.set_yticks([])\n",
        "        for c in range(np.max(targets)+1):\n",
        "            c_manifold = latent_manifold[targets == c]\n",
        "            ax1.scatter(c_manifold[:, 0], c_manifold[:, 1], marker=\".\", s=.5)\n",
        "\n",
        "        ax2.set_title(\"Predicted Labels\")\n",
        "        for c in range(np.max(remapped_pred)+1):\n",
        "            c_manifold = latent_manifold[remapped_pred == c]\n",
        "            ax2.scatter(c_manifold[:, 0], c_manifold[:, 1], marker=\".\", s=.5)\n",
        "        plt.savefig(results_dir+\"/\"+figname)\n",
        "\n",
        "def embed_test(test_data, ae):\n",
        "    latent_vecs = []\n",
        "    test_targets = []\n",
        "    for spikes, targets, snrs, num_units in test_data:\n",
        "        session_latent = []\n",
        "        possible_targets = np.arange(len(snrs))\n",
        "        hi_fidel_targets = possible_targets[snrs>=min_snr]\n",
        "        spikes = torch.FloatTensor(spikes[np.isin(targets, hi_fidel_targets)])\n",
        "        session_targets = targets[np.isin(targets, hi_fidel_targets)]\n",
        "        if \"cuda\" in ae.device:\n",
        "            spikes = spikes.cuda(0)\n",
        "        for encoder in ae.encoders:\n",
        "            session_latent.append(encoder(spikes))\n",
        "        session_latent = torch.cat(session_latent, dim=1).detach().cpu()\n",
        "        latent_vecs.append(session_latent)\n",
        "        test_targets.append(session_targets)\n",
        "    return latent_vecs, test_targets"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdBf7zTfV7tX"
      },
      "source": [
        "Run Embeddings for different minimum SNR values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "KxSUmTLkV61w",
        "outputId": "545a1620-2e40-49f5-df87-fb21586625f3"
      },
      "source": [
        "min_snrs = [0, 8, 16, 24]\n",
        "ae_is_trained = [True, False, False, False] #whether the autoencoder is already trained on the corresponding snr\n",
        "snr_acc, snr_prec, snr_recall = [], [], []\n",
        "for min_snr, is_trained in zip(min_snrs, ae_is_trained):\n",
        "    print(\"min_snr=\", min_snr)\n",
        "    if is_trained:\n",
        "        prefix=\"benchmark_snr_%s\"%min_snr\n",
        "        ae.load(prefix=prefix, on_drive=True)\n",
        "        latent_vecs, test_targets = embed_test(test_data, ae)\n",
        "    else:\n",
        "        latent_vecs, test_targets = ae.benchmark(min_snr, train_data, test_data, on_drive=True)\n",
        "    avg_stats, session_stats, remapped_preds = gt_gmm(latent_vecs, test_targets)\n",
        "    acc, prec, recall = avg_stats\n",
        "    accs, precs, recalls = [], [], []\n",
        "    accs.append(acc)\n",
        "    precs.append(prec)\n",
        "    recalls.append(recall)\n",
        "    viz_stats(avg_stats, session_stats, \"Ground-Truth GMM: minimum SNR=%s\"%min_snr, \"gtgmm_stats_snr%s\"%min_snr)\n",
        "    fignames = [\"gtgmm_tsne_snr%s_numunits%s\"%(min_snr, n) for n in [2, 10, 20]]\n",
        "    viz_tsne([2, 10, 20], latent_vecs, test_targets, remapped_preds, fignames)\n",
        "\n",
        "    avg_stats, session_stats, remapped_preds = auto_gmm(latent_vecs, test_targets)\n",
        "    acc, prec, recall = avg_stats\n",
        "    accs.append(acc)\n",
        "    precs.append(prec)\n",
        "    recalls.append(recall)\n",
        "    viz_stats(avg_stats, session_stats, \"Auto GMM: minimum SNR=%s\"%min_snr, \"autogmm_stats_snr%s\"%min_snr)\n",
        "    fignames = [\"autogmm_tsne_snr%s_numunits%s\"%(min_snr, n) for n in [2, 10, 20]]\n",
        "    viz_tsne([2, 10, 20], latent_vecs, test_targets, remapped_preds, fignames)\n",
        "\n",
        "    snr_acc.append(accs)\n",
        "    snr_prec.append(precs)\n",
        "    snr_recall.append(recalls)\n",
        "\n",
        "snr_acc = np.array(snr_acc)\n",
        "np.save(results_dir+\"/snr_acc.npy\", snr_acc)\n",
        "snr_prec = np.array(snr_prec)\n",
        "np.save(results_dir+\"/snr_prec.npy\", snr_prec)\n",
        "snr_recall = np.array(snr_recall)\n",
        "np.save(results_dir+\"/snr_recall.npy\", snr_recall)\n",
        "plt.figure()\n",
        "plt.hold = True\n",
        "plt.plot(min_snrs, snr_acc[:, 0], label=\"Average Accuracy\", c=\"C0\", ls=\"-\")\n",
        "plt.plot(min_snrs, snr_acc[:, 1], c=\"C0\", ls=\"--\")\n",
        "plt.plot(min_snrs, snr_prec[:, 0], label=\"Average Precision\", c=\"C1\", ls=\"-\")\n",
        "plt.plot(min_snrs, snr_prec[:, 1], c=\"C1\", ls=\"--\")\n",
        "plt.plot(min_snrs, snr_recall[:, 0], label=\"Average Recall\", c=\"C2\", ls=\"-\")\n",
        "plt.plot(min_snrs, snr_recall[:, 1], c=\"C2\", ls=\"--\")\n",
        "plt.hold = False\n",
        "plt.xlabel(\"Minimum SNR\")\n",
        "plt.ylabel(\"Performance\")\n",
        "plt.title(\"V0\")\n",
        "plt.savefig(results_dir+\"/v0_snr_stats\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-23-3b5d2d7e4b68>\"\u001b[0;36m, line \u001b[0;32m40\u001b[0m\n\u001b[0;31m    np.save(results_dir+)\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtUIlNCcEtOa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}