{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "BenchmarkSim.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "payCKL-mqhfP"
   },
   "source": [
    "# Benchmark Simulated Data Using SNR cutoff and Holdout Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AGA2oroEWDk1"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ydNiMYYUstbP",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "65da0097-0b91-48ab-cf63-741c3d62f215"
   },
   "source": [
    "## Mount Google Drive Data (If using Google Colaboratory)\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "except:\n",
    "    print(\"Mounting Failed.\")"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
      "Requirement already satisfied: graspologic in /usr/local/lib/python3.7/dist-packages (0.1.0)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from graspologic) (0.11.1)\n",
      "Requirement already satisfied: matplotlib<=3.3.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from graspologic) (3.2.2)\n",
      "Requirement already satisfied: POT>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from graspologic) (0.7.0)\n",
      "Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.7/dist-packages (from graspologic) (0.22.2.post1)\n",
      "Requirement already satisfied: anytree>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from graspologic) (2.8.0)\n",
      "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.7/dist-packages (from graspologic) (2.5.1)\n",
      "Requirement already satisfied: hyppo==0.1.3 in /usr/local/lib/python3.7/dist-packages (from graspologic) (0.1.3)\n",
      "Requirement already satisfied: umap-learn>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from graspologic) (0.5.1)\n",
      "Requirement already satisfied: joblib>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from graspologic) (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from graspologic) (1.19.5)\n",
      "Requirement already satisfied: graspologic-native in /usr/local/lib/python3.7/dist-packages (from graspologic) (0.1.0)\n",
      "Requirement already satisfied: scipy>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from graspologic) (1.4.1)\n",
      "Requirement already satisfied: gensim<=3.9.0,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from graspologic) (3.8.3)\n",
      "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.7/dist-packages (from seaborn>=0.11.0->graspologic) (1.1.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib<=3.3.0,>=3.0.0->graspologic) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<=3.3.0,>=3.0.0->graspologic) (1.3.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<=3.3.0,>=3.0.0->graspologic) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<=3.3.0,>=3.0.0->graspologic) (2.8.1)\n",
      "Requirement already satisfied: cython>=0.23 in /usr/local/lib/python3.7/dist-packages (from POT>=0.7.0->graspologic) (0.29.22)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from anytree>=2.8.0->graspologic) (1.15.0)\n",
      "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.1->graspologic) (4.4.2)\n",
      "Requirement already satisfied: numba>=0.46 in /usr/local/lib/python3.7/dist-packages (from hyppo==0.1.3->graspologic) (0.51.2)\n",
      "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.7/dist-packages (from umap-learn>=0.4.6->graspologic) (0.5.2)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim<=3.9.0,>=3.8.0->graspologic) (5.0.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23->seaborn>=0.11.0->graspologic) (2018.9)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.46->hyppo==0.1.3->graspologic) (56.0.0)\n",
      "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.46->hyppo==0.1.3->graspologic) (0.34.0)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## External Libraries\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import end2end\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from autoencode import AEEnsemble\n",
    "from datasets import UnsupervisedDataset, SupervisedDataset, BenchmarkDataset\n",
    "from sklearn.mixture import GaussianMixture\n",
    "!pip install graspologic\n",
    "from graspologic.utils import remap_labels\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=2)\n",
    "sns.set_theme()\n",
    "sns.set_context(\"paper\")\n",
    "\n",
    "# General Data Directory ##TODO: Please fill in the appropriate directory\n",
    "os.chdir(\"/content/\")\n",
    "data_dir = \"./gdrive/MyDrive/pedreira\"\n",
    "results_dir = \"./gdrive/MyDrive/results\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IUkQnuJ3THva"
   },
   "source": [
    "Define Datasets and AutoEncoder Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q8jI7ndcSiqN",
    "outputId": "21dfc1b5-77dc-40c7-b333-77ce946fe6c8"
   },
   "source": [
    "sup_data = BenchmarkDataset(data_dir)\n",
    "test_idx = []\n",
    "for i in range(2, 21):\n",
    "    test_idx.append(list(sup_data.num_units).index(i))\n",
    "train_idx = np.arange(len(sup_data))\n",
    "not_test_mask = np.logical_not(np.isin(train_idx, test_idx))\n",
    "train_idx = train_idx[not_test_mask]\n",
    "train_data = torch.utils.data.Subset(sup_data, train_idx)\n",
    "test_data = torch.utils.data.Subset(sup_data, test_idx)\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "ae = AEEnsemble(\n",
    "    optim=torch.optim.Adam,\n",
    "    convolutional_encoding=False, \n",
    "    batch_size=32, \n",
    "    epochs=50, \n",
    "    lr=(0.001, 0.001, 0.001),\n",
    "    device=device, \n",
    "    activ=nn.ReLU\n",
    ")"
   ],
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Using cuda:0\n",
      "Using cuda:0\n",
      "Using cuda:0\n",
      "Using cuda:0\n",
      "Using cuda:0\n",
      "Using cuda:0\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6phQWnjUTMV6"
   },
   "source": [
    "Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "WRLcWaCmTLgx"
   },
   "source": [
    "def gt_gmm(latent_vecs, test_targets):\n",
    "    test_acc = []\n",
    "    test_prec = []\n",
    "    test_recall = []\n",
    "    session_weights = []\n",
    "    remapped_preds = []\n",
    "    for (i, latent), targets in zip(enumerate(latent_vecs), test_targets):\n",
    "        session_weights.append(len(targets))\n",
    "        units = set(targets)\n",
    "        num_units = len(units)\n",
    "        gmm = GaussianMixture(n_components=num_units)\n",
    "        pred = gmm.fit_predict(latent)\n",
    "        remapped_pred = remap_labels(targets, pred)\n",
    "        remapped_preds.append(remapped_pred)\n",
    "        prec = []\n",
    "        recall = []\n",
    "        for unit in units:\n",
    "            TP = np.sum(np.logical_and(remapped_pred==unit, targets==unit))\n",
    "            FP = np.sum(np.logical_and(remapped_pred==unit, targets!=unit))\n",
    "            if FP == 0:\n",
    "                prec.append(1)\n",
    "            else:\n",
    "                prec.append(TP / (TP + FP))\n",
    "            TN = np.sum(np.logical_and(remapped_pred!=unit, targets!=unit))\n",
    "            FN = np.sum(np.logical_and(remapped_pred!=unit, targets==unit))\n",
    "            if FN == 0:\n",
    "                recall.append(1)\n",
    "            else:\n",
    "                recall.append(TP / (TP + FN))\n",
    "\n",
    "        test_prec.append(np.mean(prec))\n",
    "        test_recall.append(np.mean(recall))\n",
    "        test_acc.append(sum(remapped_pred==targets)/len(targets))\n",
    "\n",
    "    session_weights = np.array(session_weights) / sum(session_weights)\n",
    "    avg_acc = np.sum(test_acc*session_weights)\n",
    "    avg_prec = np.mean(test_acc)\n",
    "    avg_recall = np.mean(test_recall)\n",
    "    avg_stats = avg_acc, avg_prec, avg_recall\n",
    "    session_stats = test_acc, test_prec, test_recall\n",
    "    return avg_stats, session_stats, remapped_preds\n",
    "\n",
    "def auto_gmm(latent_vecs, test_targets):\n",
    "    test_acc = []\n",
    "    test_prec = []\n",
    "    test_recall = []\n",
    "    session_weights = []\n",
    "    remapped_preds = []\n",
    "    max_n_comps = 21\n",
    "    for (i, latent), targets in zip(enumerate(latent_vecs), test_targets):\n",
    "        session_weights.append(len(targets))\n",
    "        units = set(targets)\n",
    "        num_units = len(units)\n",
    "        bics = []\n",
    "        preds = []\n",
    "        for n_comps in range(1, max_n_comps+1):\n",
    "            gmm = GaussianMixture(n_components=n_comps)\n",
    "            preds.append(gmm.fit_predict(latent))\n",
    "            bics.append(gmm.bic(latent))\n",
    "        pred = preds[np.argmin(bics)]\n",
    "        print(\"predicted num_units=\", np.argmin(bics)+1)\n",
    "        print(\"true num_units=\", num_units)\n",
    "        remapped_pred = remap_labels(targets, pred)\n",
    "        remapped_preds.append(remapped_pred)\n",
    "        prec = []\n",
    "        recall = []\n",
    "        for unit in units:\n",
    "            TP = np.sum(np.logical_and(remapped_pred==unit, targets==unit))\n",
    "            FP = np.sum(np.logical_and(remapped_pred==unit, targets!=unit))\n",
    "            if FP == 0:\n",
    "                prec.append(1)\n",
    "            else:\n",
    "                prec.append(TP / (TP + FP))\n",
    "            TN = np.sum(np.logical_and(remapped_pred!=unit, targets!=unit))\n",
    "            FN = np.sum(np.logical_and(remapped_pred!=unit, targets==unit))\n",
    "            if FN == 0:\n",
    "                recall.append(1)\n",
    "            else:\n",
    "                recall.append(TP / (TP + FN))\n",
    "\n",
    "        test_prec.append(np.mean(prec))\n",
    "        test_recall.append(np.mean(recall))\n",
    "        test_acc.append(sum(remapped_pred==targets)/len(targets))\n",
    "\n",
    "    session_weights = np.array(session_weights) / sum(session_weights)\n",
    "    avg_acc = np.sum(test_acc*session_weights)\n",
    "    avg_prec = np.mean(test_acc)\n",
    "    avg_recall = np.mean(test_recall)\n",
    "    avg_stats = avg_acc, avg_prec, avg_recall\n",
    "    session_stats = test_acc, test_prec, test_recall\n",
    "    return avg_stats, session_stats, remapped_preds\n",
    "\n",
    "def viz_stats(avg_stats, session_stats, _title, figname):\n",
    "    avg_acc, avg_prec, avg_recall = avg_stats\n",
    "    test_acc, test_prec, test_recall = session_stats\n",
    "    print(\"Average Accuracy=\", avg_acc)\n",
    "    print(\"Average Precision=\", avg_prec)\n",
    "    print(\"Average Recall=\", avg_recall)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.hold = True\n",
    "    plt.plot(np.arange(2, 21), test_acc, label=\"Accuracy\")\n",
    "    plt.plot(np.arange(2, 21), test_prec, label=\"Precision\")\n",
    "    plt.plot(np.arange(2, 21), test_recall, label=\"Recall\")\n",
    "    plt.hold = False\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"True Number of Units (before SNR)\")\n",
    "    plt.ylabel(\"Performance\")\n",
    "    plt.title(_title)\n",
    "    plt.savefig(results_dir+\"/\"+figname)\n",
    "\n",
    "def viz_tsne(unit_nums, latent_vecs, test_targets, remapped_preds, fignames):\n",
    "    for idx, figname in zip(unit_nums, fignames):\n",
    "        i = idx - 2 #accounting for offset since idx=0 has 2 units\n",
    "        latent = latent_vecs[i]\n",
    "        targets = test_targets[i]\n",
    "        remapped_pred = remapped_preds[i]\n",
    "\n",
    "        # Plot tsne\n",
    "        latent_manifold = tsne.fit_transform(latent.cpu())\n",
    "\n",
    "        fig, (ax1, ax2) = plt.subplots(ncols=2, sharex=True, sharey=True)\n",
    "        ax1.set_title(\"Ground Truth Labels\")\n",
    "        ax1.set_xticks([])\n",
    "        ax1.set_yticks([])\n",
    "        for c in range(np.max(targets)+1):\n",
    "            c_manifold = latent_manifold[targets == c]\n",
    "            ax1.scatter(c_manifold[:, 0], c_manifold[:, 1], marker=\".\", s=.5)\n",
    "\n",
    "        ax2.set_title(\"Predicted Labels\")\n",
    "        for c in range(np.max(remapped_pred)+1):\n",
    "            c_manifold = latent_manifold[remapped_pred == c]\n",
    "            ax2.scatter(c_manifold[:, 0], c_manifold[:, 1], marker=\".\", s=.5)\n",
    "        plt.savefig(results_dir+\"/\"+figname)\n",
    "\n",
    "def embed_test(test_data, ae):\n",
    "    latent_vecs = []\n",
    "    test_targets = []\n",
    "    for spikes, targets, snrs, num_units in test_data:\n",
    "        session_latent = []\n",
    "        possible_targets = np.arange(len(snrs))\n",
    "        hi_fidel_targets = possible_targets[snrs>=min_snr]\n",
    "        spikes = torch.FloatTensor(spikes[np.isin(targets, hi_fidel_targets)])\n",
    "        session_targets = targets[np.isin(targets, hi_fidel_targets)]\n",
    "        if \"cuda\" in ae.device:\n",
    "            spikes = spikes.cuda(0)\n",
    "        for encoder in ae.encoders:\n",
    "            session_latent.append(encoder(spikes))\n",
    "        session_latent = torch.cat(session_latent, dim=1).detach().cpu()\n",
    "        latent_vecs.append(session_latent)\n",
    "        test_targets.append(session_targets)\n",
    "    return latent_vecs, test_targets"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WdBf7zTfV7tX"
   },
   "source": [
    "Run Embeddings for different minimum SNR values"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 562
    },
    "id": "KxSUmTLkV61w",
    "outputId": "25ae70df-e865-43a7-f190-c6276e2c018b"
   },
   "source": [
    "min_snrs = [0, 8, 16, 24]\n",
    "ae_is_trained = [True, True, False, False] #whether the autoencoder is already trained on the corresponding snr\n",
    "#Train Loop\n",
    "for min_snr, is_trained in zip(min_snrs, ae_is_trained):\n",
    "    print(\"min_snr=\", min_snr)\n",
    "    if is_trained:\n",
    "        continue\n",
    "    ae = AEEnsemble(\n",
    "    optim=torch.optim.Adam,\n",
    "    convolutional_encoding=False, \n",
    "    batch_size=32, \n",
    "    epochs=50, \n",
    "    lr=(0.001, 0.001, 0.001),\n",
    "    device=device, \n",
    "    activ=nn.ReLU\n",
    ")\n",
    "    ae.benchmark(min_snr, train_data, test_data, on_drive=True)\n",
    "\n",
    "#Eval Loop\n",
    "snr_acc, snr_prec, snr_recall = [], [], []\n",
    "for min_snr, is_trained in zip(min_snrs, ae_is_trained):\n",
    "    print(\"min_snr=\", min_snr)\n",
    "    prefix=\"benchmark_snr_%s\"%min_snr\n",
    "    ae.load(prefix=prefix, on_drive=True)\n",
    "    latent_vecs, test_targets = embed_test(test_data, ae)\n",
    "    \n",
    "    avg_stats, session_stats, remapped_preds = gt_gmm(latent_vecs, test_targets)\n",
    "    acc, prec, recall = avg_stats\n",
    "    accs, precs, recalls = [], [], []\n",
    "    accs.append(acc)\n",
    "    precs.append(prec)\n",
    "    recalls.append(recall)\n",
    "    viz_stats(avg_stats, session_stats, \"Ground-Truth GMM: minimum SNR=%s\"%min_snr, \"gtgmm_stats_snr%s\"%min_snr)\n",
    "    fignames = [\"gtgmm_tsne_snr%s_numunits%s\"%(min_snr, n) for n in [2, 10, 20]]\n",
    "    viz_tsne([2, 10, 20], latent_vecs, test_targets, remapped_preds, fignames)\n",
    "\n",
    "    avg_stats, session_stats, remapped_preds = auto_gmm(latent_vecs, test_targets)\n",
    "    acc, prec, recall = avg_stats\n",
    "    accs.append(acc)\n",
    "    precs.append(prec)\n",
    "    recalls.append(recall)\n",
    "    viz_stats(avg_stats, session_stats, \"Auto GMM: minimum SNR=%s\"%min_snr, \"autogmm_stats_snr%s\"%min_snr)\n",
    "    fignames = [\"autogmm_tsne_snr%s_numunits%s\"%(min_snr, n) for n in [2, 10, 20]]\n",
    "    viz_tsne([2, 10, 20], latent_vecs, test_targets, remapped_preds, fignames)\n",
    "\n",
    "    snr_acc.append(accs)\n",
    "    snr_prec.append(precs)\n",
    "    snr_recall.append(recalls)\n",
    "\n",
    "snr_acc = np.array(snr_acc)\n",
    "np.save(results_dir+\"/snr_acc.npy\", snr_acc)\n",
    "snr_prec = np.array(snr_prec)\n",
    "np.save(results_dir+\"/snr_prec.npy\", snr_prec)\n",
    "snr_recall = np.array(snr_recall)\n",
    "np.save(results_dir+\"/snr_recall.npy\", snr_recall)\n",
    "plt.figure()\n",
    "plt.hold = True\n",
    "plt.plot(min_snrs, snr_acc[:, 0], label=\"Average Accuracy\", c=\"C0\", ls=\"-\")\n",
    "plt.plot(min_snrs, snr_acc[:, 1], c=\"C0\", ls=\"--\")\n",
    "plt.plot(min_snrs, snr_prec[:, 0], label=\"Average Precision\", c=\"C1\", ls=\"-\")\n",
    "plt.plot(min_snrs, snr_prec[:, 1], c=\"C1\", ls=\"--\")\n",
    "plt.plot(min_snrs, snr_recall[:, 0], label=\"Average Recall\", c=\"C2\", ls=\"-\")\n",
    "plt.plot(min_snrs, snr_recall[:, 1], c=\"C2\", ls=\"--\")\n",
    "plt.hold = False\n",
    "plt.xlabel(\"Minimum SNR\")\n",
    "plt.ylabel(\"Performance\")\n",
    "plt.title(\"V0\")\n",
    "plt.savefig(results_dir+\"/v0_snr_stats\")"
   ],
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "min_snr= 0\n",
      "min_snr= 8\n",
      "min_snr= 16\n",
      "Using cuda:0\n",
      "Using cuda:0\n",
      "Using cuda:0\n",
      "Using cuda:0\n",
      "Using cuda:0\n",
      "Using cuda:0\n",
      "\n",
      "EPOCH 1 of 50\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-8-ecb8a83a61ae>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     15\u001B[0m     \u001B[0mactiv\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mnn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mReLU\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     16\u001B[0m )\n\u001B[0;32m---> 17\u001B[0;31m     \u001B[0mae\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbenchmark\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmin_snr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_data\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_data\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mon_drive\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     18\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     19\u001B[0m \u001B[0;31m#Eval Loop\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/content/autoencode.py\u001B[0m in \u001B[0;36mbenchmark\u001B[0;34m(self, min_snr, train_data, test_data, on_drive)\u001B[0m\n\u001B[1;32m    191\u001B[0m                 \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    192\u001B[0m                 \u001B[0;32mfor\u001B[0m \u001B[0midx\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mbatch\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 193\u001B[0;31m                     \u001B[0mspikes\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtargets\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msnrs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnum_units\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtrain_data\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0midx\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    194\u001B[0m                     \u001B[0mpossible_targets\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0marange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msnrs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    195\u001B[0m                     \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0many\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msnrs\u001B[0m\u001B[0;34m>=\u001B[0m\u001B[0mmin_snr\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;31m#spike sessions with no units above SNR threshold\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataset.py\u001B[0m in \u001B[0;36m__getitem__\u001B[0;34m(self, idx)\u001B[0m\n\u001B[1;32m    328\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    329\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__getitem__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0midx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 330\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mindices\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0midx\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    331\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    332\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__len__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/content/datasets.py\u001B[0m in \u001B[0;36m__getitem__\u001B[0;34m(self, idx)\u001B[0m\n\u001B[1;32m    156\u001B[0m             \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mchannel_dir\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"spikes.npy\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mallow_pickle\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    157\u001B[0m         ).squeeze()\n\u001B[0;32m--> 158\u001B[0;31m         \u001B[0mspikes\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0marray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0msignal\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mresample\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mspike\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_input_dim\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mspike\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mspikes\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    159\u001B[0m         \u001B[0msnrs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msession_dir\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"snrs.npy\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mallow_pickle\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    160\u001B[0m         \u001B[0mtargets\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mspike_classes\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0midx\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msqueeze\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/content/datasets.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    156\u001B[0m             \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mchannel_dir\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"spikes.npy\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mallow_pickle\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    157\u001B[0m         ).squeeze()\n\u001B[0;32m--> 158\u001B[0;31m         \u001B[0mspikes\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0marray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0msignal\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mresample\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mspike\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_input_dim\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mspike\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mspikes\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    159\u001B[0m         \u001B[0msnrs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msession_dir\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"snrs.npy\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mallow_pickle\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    160\u001B[0m         \u001B[0mtargets\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mspike_classes\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0midx\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msqueeze\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/scipy/signal/signaltools.py\u001B[0m in \u001B[0;36mresample\u001B[0;34m(x, num, t, axis, window)\u001B[0m\n\u001B[1;32m   2912\u001B[0m     \u001B[0;31m# Inverse transform\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2913\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mreal_input\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2914\u001B[0;31m         \u001B[0my\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msp_fft\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mirfft\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mY\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnum\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0maxis\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2915\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2916\u001B[0m         \u001B[0my\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msp_fft\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mifft\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mY\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0maxis\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moverwrite_x\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "BtUIlNCcEtOa"
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}